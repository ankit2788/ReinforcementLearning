{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "1. Data collection --> __Done__\n",
    "2. Create environment --> __Done__<br>\n",
    "2.1. Set up Action space (Discrete) --> __Done__ <br>\n",
    "2.2. Set up State space (Continuous) --> __Done__ <br>\n",
    "3. Develop RL Agent (DQN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with RL:\n",
    "1. RL known to be divergent/ unstable when delaing with non linear approximators (such as NNs). \n",
    "<br>__Reason__: sequential updates.\n",
    "<br>__Solution__: \n",
    "    1. Experience replay (DQN)\n",
    "    2. Update action values periodically, rather than at every iteration, i.e. use 2 models. 1 Q network and other target network\n",
    "\n",
    "### Advantages of this model:\n",
    "1. __Model free__: No prior knowledge of environment needed. Samples are generated from emulator.\n",
    "2. __Off Policy__: Learns about the *greedy policy* while following epsilon-greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ankitgupta/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks\n"
     ]
    }
   ],
   "source": [
    "# set the environment path\n",
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "path = f'{cwd}/../lib'\n",
    "\n",
    "os.environ[\"PORT_MGMT_PATH\"] = path\n",
    "\n",
    "if os.environ[\"PORT_MGMT_PATH\"] not in sys.path:\n",
    "    sys.path.append(os.environ[\"PORT_MGMT_PATH\"])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from logging.config import dictConfig\n",
    "import logging\n",
    "import loggingConfig\n",
    "\n",
    "\n",
    "dictConfig(loggingConfig.DEFAULT_LOGGING)\n",
    "Logger = logging.getLogger(\"Training\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import Environments\n",
    "from importlib import reload\n",
    "\n",
    "import Actions\n",
    "from Actions.ActionSelection import EpsilonGreedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Environments' from '/Users/ankitgupta/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/Environments.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(Environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 08:41:35 INFO     Environments    Data Loaded!\n",
      "2021-02-01 08:41:35 INFO     Actions         Action Space set with 7 possible actions \n",
      "2021-02-01 08:41:35 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "    [-0.01,0.01],\n",
    "    [-0.02,0.02],\n",
    "    [-0.03,0.03],\n",
    "    [0.01,-0.01],\n",
    "    [0.02,-0.02],\n",
    "    [0.03,-0.03],\n",
    "    [-0.00,0.00],\n",
    "]\n",
    "\n",
    "env = Environments.Portfolio(assets = [\"APA\", \"BMY\"], initialWeight = [0.5, 0.5], \\\n",
    "                 nhistoricalDays = 30, \\\n",
    "                 actions = actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(30):\\n    \\n    # take random action\\n    action = random.choice(actions)\\n    nextState, reward, dead = env.step(action = action)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(30):\n",
    "    \n",
    "    # take random action\n",
    "    action = random.choice(actions)\n",
    "    nextState, reward, dead = env.step(action = action)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>196.0</td>\n",
       "      <td>999804.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Asset_APA  Asset_BMY      Cash   Cost       AUM\n",
       "0  2003-12-31    14946.0    32503.0  19823.51  196.0  999804.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999804.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.currentPortfolioValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentConfig  = os.path.join(path, \"RLAGENTS_CONFIG.ini\" )\n",
    "#savePath    = os.path.join(os.environ[\"RL_PATH\"], \"models\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RLAgent' from '/Users/ankitgupta/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/RLAgent.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(RLAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'finalExploration' and 'nbIterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-072531cba3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDQNAgent\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mRLAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magentConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/RLAgent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, configFile, model, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Action selection method & model used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mActionExploration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethodExploration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__time\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d%H%M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/Actions/ActionSelection.py\u001b[0m in \u001b[0;36mActionExploration\u001b[0;34m(config, method)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EPSILON_GREEDY\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mEpsilonGreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"UCB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'finalExploration' and 'nbIterations'"
     ]
    }
   ],
   "source": [
    "DQNAgent  = RLAgent.DQN(env = env, configFile = agentConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the model\n",
    "#savePath    = os.path.join(os.environ[\"RL_PATH\"], \"models\" )\n",
    "_time       = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Agent = DQNAgent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode= \"TRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:20:51 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "_currentState = env.currentState\n",
    "\n",
    "_episodicReward = 0\n",
    "_dead = False\n",
    "_thisstepsTaken = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:23:15 INFO     Environments    Environment reset\n",
      "2021-01-21 17:23:15 INFO     Training        Episode: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:42<13:31, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:23:58 INFO     Environments    Environment reset\n",
      "2021-01-21 17:23:58 INFO     Training        Episode: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:22<12:33, 41.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:24:38 INFO     Environments    Environment reset\n",
      "2021-01-21 17:24:38 INFO     Training        Episode: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:02<11:43, 41.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:25:18 INFO     Environments    Environment reset\n",
      "2021-01-21 17:25:18 INFO     Training        Episode: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:42<10:52, 40.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:25:57 INFO     Environments    Environment reset\n",
      "2021-01-21 17:25:57 INFO     Training        Episode: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:21<10:06, 40.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:26:37 INFO     Environments    Environment reset\n",
      "2021-01-21 17:26:37 INFO     Training        Episode: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [04:06<09:42, 41.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:27:21 INFO     Environments    Environment reset\n",
      "2021-01-21 17:27:21 INFO     Training        Episode: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:45<08:53, 41.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:28:01 INFO     Environments    Environment reset\n",
      "2021-01-21 17:28:01 INFO     Training        Episode: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [05:25<08:08, 40.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:28:41 INFO     Environments    Environment reset\n",
      "2021-01-21 17:28:41 INFO     Training        Episode: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:26<08:32, 46.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:29:41 INFO     Environments    Environment reset\n",
      "2021-01-21 17:29:41 INFO     Training        Episode: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [07:18<08:04, 48.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:30:34 INFO     Environments    Environment reset\n",
      "2021-01-21 17:30:34 INFO     Training        Episode: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [08:02<07:02, 46.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:31:17 INFO     Environments    Environment reset\n",
      "2021-01-21 17:31:17 INFO     Training        Episode: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [08:44<06:03, 45.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:31:59 INFO     Environments    Environment reset\n",
      "2021-01-21 17:31:59 INFO     Training        Episode: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:24<05:06, 43.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:32:39 INFO     Environments    Environment reset\n",
      "2021-01-21 17:32:39 INFO     Training        Episode: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [10:03<04:15, 42.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:33:19 INFO     Environments    Environment reset\n",
      "2021-01-21 17:33:19 INFO     Training        Episode: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [10:43<03:28, 41.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:33:59 INFO     Environments    Environment reset\n",
      "2021-01-21 17:33:59 INFO     Training        Episode: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [11:23<02:44, 41.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:34:39 INFO     Environments    Environment reset\n",
      "2021-01-21 17:34:39 INFO     Training        Episode: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:02<02:01, 40.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:35:18 INFO     Environments    Environment reset\n",
      "2021-01-21 17:35:18 INFO     Training        Episode: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [12:42<01:20, 40.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:35:57 INFO     Environments    Environment reset\n",
      "2021-01-21 17:35:57 INFO     Training        Episode: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [13:21<00:39, 39.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:36:37 INFO     Environments    Environment reset\n",
      "2021-01-21 17:36:37 INFO     Training        Episode: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [15:59<00:00, 47.97s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = []\n",
    "mode = \"TRAIN\"\n",
    "count = 0\n",
    "nbEpisodes = 20\n",
    "for _thisepisode in tqdm(range(nbEpisodes)):\n",
    "\n",
    "    # reset the environment\n",
    "    env.reset()\n",
    "    _currentState = env.currentState\n",
    "    \n",
    "    _episodicReward = 0\n",
    "    _dead = False\n",
    "    _thisstepsTaken = 0\n",
    "    Logger.info(f\"Episode: {_thisepisode}\")\n",
    "\n",
    "    #Agent.Tensorboard.step = _thisepisode\n",
    "        \n",
    "\n",
    "    while not _dead:\n",
    "\n",
    "        # get the action from agent\n",
    "        actionIndex = Agent.getAction(_currentState, mode = mode)\n",
    "        action = Agent.env.action_space.actions[actionIndex]\n",
    "        \n",
    "\n",
    "        # perform the action\n",
    "        _nextState, _reward, _dead = env.step(action)\n",
    "\n",
    "        # record into memory\n",
    "        Agent.updateMemory(_currentState, actionIndex, _reward, _nextState, _dead)\n",
    "\n",
    "        # train the agent and update the state\n",
    "        Agent.trainAgent(_dead, batch_size = Agent.Qmodel.batchSize)\n",
    "        if count == 100:\n",
    "            mymemory = Agent.memory.copy()\n",
    "            myloss = Agent.callbacks[1]\n",
    "            mymodel = Agent.Qmodel.model\n",
    "        \n",
    "        \n",
    "        # update States\n",
    "        _currentState = _nextState\n",
    "        _thisstepsTaken += 1\n",
    "        count += 1\n",
    "\n",
    "        _episodicReward += _reward\n",
    "\n",
    "        # if game over, then exit the loop\n",
    "        if _dead == True:\n",
    "            break   \n",
    "\n",
    "\n",
    "    # ---- For logging ------\n",
    "    # In case of Neural networks, create tensorboard flow\n",
    "    #Agent.updateLoggerInfo(episodeCount = _thisepisode, episodicReward = _episodicReward, \\\n",
    "    #                        episodicStepsTaken = _thisstepsTaken, mode = \"TRAIN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [12.21529769897461], 'mean_squared_error': [12.215298]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myloss.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mymemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>196.00</td>\n",
       "      <td>9.998040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>14641.0</td>\n",
       "      <td>33166.0</td>\n",
       "      <td>19819.51</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.008764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>15572.0</td>\n",
       "      <td>31210.0</td>\n",
       "      <td>19807.40</td>\n",
       "      <td>12.11</td>\n",
       "      <td>1.014572e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>15572.0</td>\n",
       "      <td>31210.0</td>\n",
       "      <td>19807.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.019141e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>15264.0</td>\n",
       "      <td>31868.0</td>\n",
       "      <td>19803.32</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.019902e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>119858.0</td>\n",
       "      <td>-487.0</td>\n",
       "      <td>-76233.91</td>\n",
       "      <td>7.12</td>\n",
       "      <td>1.730450e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>117600.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-76247.75</td>\n",
       "      <td>13.84</td>\n",
       "      <td>1.673895e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>116473.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>-76254.45</td>\n",
       "      <td>6.70</td>\n",
       "      <td>1.588678e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>115348.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>-76260.80</td>\n",
       "      <td>6.35</td>\n",
       "      <td>1.664573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>114222.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>-76267.46</td>\n",
       "      <td>6.66</td>\n",
       "      <td>1.624728e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Asset_APA  Asset_BMY      Cash    Cost           AUM\n",
       "0     2003-12-31    14946.0    32503.0  19823.51  196.00  9.998040e+05\n",
       "1     2004-01-02    14641.0    33166.0  19819.51    4.00  1.008764e+06\n",
       "2     2004-01-05    15572.0    31210.0  19807.40   12.11  1.014572e+06\n",
       "3     2004-01-06    15572.0    31210.0  19807.40    0.00  1.019141e+06\n",
       "4     2004-01-07    15264.0    31868.0  19803.32    4.08  1.019902e+06\n",
       "...          ...        ...        ...       ...     ...           ...\n",
       "4272  2020-12-18   119858.0     -487.0 -76233.91    7.12  1.730450e+06\n",
       "4273  2020-12-21   117600.0       61.0 -76247.75   13.84  1.673895e+06\n",
       "4274  2020-12-22   116473.0      331.0 -76254.45    6.70  1.588678e+06\n",
       "4275  2020-12-23   115348.0      590.0 -76260.80    6.35  1.664573e+06\n",
       "4276  2020-12-24   114222.0      863.0 -76267.46    6.66  1.624728e+06\n",
       "\n",
       "[4277 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent.env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets run the model now on a new episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-21 17:45:40 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "_currentState = env.currentState\n",
    "\n",
    "_episodicReward = 0\n",
    "_dead = False\n",
    "_thisstepsTaken = 0\n",
    "\n",
    "#Agent.Tensorboard.step = _thisepisode\n",
    "mode = \"TEST\"\n",
    "\n",
    "while not _dead:\n",
    "\n",
    "    # get the action from agent\n",
    "    \n",
    "    state = np.array(_currentState).reshape(1, Agent.env.observation_space.n)\n",
    "    _actionsValues      = Agent.Qmodel.predict(state)[0] \n",
    "    actionIndex  = np.argmax(_actionsValues)\n",
    "    \n",
    "\n",
    "    \n",
    "    #actionIndex = Agent.getAction(_currentState, mode = mode)\n",
    "    action = Agent.env.action_space.actions[actionIndex]\n",
    "\n",
    "\n",
    "    # perform the action\n",
    "    _nextState, _reward, _dead = env.step(action)\n",
    "\n",
    "    #update state and \n",
    "\n",
    "\n",
    "    # update States\n",
    "    _currentState = _nextState\n",
    "    _thisstepsTaken += 1\n",
    "    count += 1\n",
    "\n",
    "    _episodicReward += _reward\n",
    "\n",
    "    # if game over, then exit the loop\n",
    "    if _dead == True:\n",
    "        break   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>196.00</td>\n",
       "      <td>9.998040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>14641.0</td>\n",
       "      <td>33166.0</td>\n",
       "      <td>19819.51</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.008764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>33818.0</td>\n",
       "      <td>19815.47</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1.013888e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>14023.0</td>\n",
       "      <td>34475.0</td>\n",
       "      <td>19811.41</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.018447e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>13715.0</td>\n",
       "      <td>35132.0</td>\n",
       "      <td>19807.34</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.019800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>493279222.0</td>\n",
       "      <td>-122900708.0</td>\n",
       "      <td>-3610854.48</td>\n",
       "      <td>317.31</td>\n",
       "      <td>-1.991330e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>493409120.0</td>\n",
       "      <td>-122932256.0</td>\n",
       "      <td>-3611651.01</td>\n",
       "      <td>796.53</td>\n",
       "      <td>-2.995150e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>493610814.0</td>\n",
       "      <td>-122980557.0</td>\n",
       "      <td>-3612849.07</td>\n",
       "      <td>1198.06</td>\n",
       "      <td>-5.885239e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>494027616.0</td>\n",
       "      <td>-123076361.0</td>\n",
       "      <td>-3615203.17</td>\n",
       "      <td>2354.10</td>\n",
       "      <td>-2.095452e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>494169392.0</td>\n",
       "      <td>-123110713.0</td>\n",
       "      <td>-3616041.35</td>\n",
       "      <td>838.18</td>\n",
       "      <td>-4.009719e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Asset_APA    Asset_BMY        Cash     Cost           AUM\n",
       "0     2003-12-31      14946.0      32503.0    19823.51   196.00  9.998040e+05\n",
       "1     2004-01-02      14641.0      33166.0    19819.51     4.00  1.008764e+06\n",
       "2     2004-01-05      14331.0      33818.0    19815.47     4.04  1.013888e+06\n",
       "3     2004-01-06      14023.0      34475.0    19811.41     4.06  1.018447e+06\n",
       "4     2004-01-07      13715.0      35132.0    19807.34     4.07  1.019800e+06\n",
       "...          ...          ...          ...         ...      ...           ...\n",
       "4272  2020-12-18  493279222.0 -122900708.0 -3610854.48   317.31 -1.991330e+08\n",
       "4273  2020-12-21  493409120.0 -122932256.0 -3611651.01   796.53 -2.995150e+08\n",
       "4274  2020-12-22  493610814.0 -122980557.0 -3612849.07  1198.06 -5.885239e+08\n",
       "4275  2020-12-23  494027616.0 -123076361.0 -3615203.17  2354.10 -2.095452e+08\n",
       "4276  2020-12-24  494169392.0 -123110713.0 -3616041.35   838.18 -4.009719e+08\n",
       "\n",
       "[4277 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent.env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1343, 2: 1353, 5: 1405, 6: 1338, 3: 1319, 4: 1398, 0: 1844}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dict = {}\n",
    "_currentState = Agent.env.currentState\n",
    "for i in range(10000):\n",
    "    action = Agent.getAction(_currentState, mode = mode)\n",
    "    try:\n",
    "        _dict[action]\n",
    "    except KeyError:\n",
    "        _dict[action] = 0\n",
    "    \n",
    "    _dict[action] += 1\n",
    "    \n",
    "_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Agent.memory[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349.029930391902"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets test it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-12b39dd0e738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TEST\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_thisepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNbEpisodesTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "mode = \"TEST\"\n",
    "for _thisepisode in tqdm(range(Agent.NbEpisodesTest)):\n",
    "\n",
    "    # reset the environment\n",
    "    env.reset()\n",
    "    _currentState = env.currentState\n",
    "    \n",
    "    _episodicReward = 0\n",
    "    _dead = False\n",
    "    _thisstepsTaken = 0\n",
    "    Logger.info(f\"Episode: {_thisepisode+1}\")\n",
    "\n",
    "    #Agent.Tensorboard.step = _thisepisode\n",
    "        \n",
    "\n",
    "    while not _dead:\n",
    "\n",
    "        # get the action from agent\n",
    "        action = Agent.getAction(_currentState, mode = mode)\n",
    "        \n",
    "\n",
    "        # perform the action\n",
    "        _nextState, _reward, _dead = env.step(action)\n",
    "\n",
    "        # record into memory\n",
    "        #Agent.updateMemory(_currentState, action, _reward, _nextState, _dead)\n",
    "\n",
    "        # train the agent and update the state\n",
    "        \"\"\"\n",
    "        history = Agent.trainAgent(batch_size = Agent.Qmodel.batchSize)\n",
    "        if history  is not None:\n",
    "            loss.append(history.history[\"loss\"])\n",
    "        \"\"\"\n",
    "        #Agent.trainAgent(_dead, batch_size = Agent.Qmodel.batchSize)\n",
    "        \n",
    "        # update States\n",
    "        _currentState = _nextState\n",
    "        _thisstepsTaken += 1\n",
    "\n",
    "        _episodicReward += _reward\n",
    "\n",
    "        # if game over, then exit the loop\n",
    "        if _dead == True:\n",
    "            break   \n",
    "\n",
    "\n",
    "    # ---- For logging ------\n",
    "    # In case of Neural networks, create tensorboard flow\n",
    "    #Agent.updateLoggerInfo(episodeCount = _thisepisode, episodicReward = _episodicReward, \\\n",
    "    #                        episodicStepsTaken = _thisstepsTaken, mode = \"TRAIN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>196.0</td>\n",
       "      <td>9.998040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008424e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.013891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.018464e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019353e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.300535e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.257283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.227520e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.223408e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19823.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.223053e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Asset_APA  Asset_BMY      Cash   Cost           AUM\n",
       "0     2003-12-31    14946.0    32503.0  19823.51  196.0  9.998040e+05\n",
       "1     2004-01-02    14946.0    32503.0  19823.51    0.0  1.008424e+06\n",
       "2     2004-01-05    14946.0    32503.0  19823.51    0.0  1.013891e+06\n",
       "3     2004-01-06    14946.0    32503.0  19823.51    0.0  1.018464e+06\n",
       "4     2004-01-07    14946.0    32503.0  19823.51    0.0  1.019353e+06\n",
       "...          ...        ...        ...       ...    ...           ...\n",
       "4272  2020-12-18    14946.0    32503.0  19823.51    0.0  2.300535e+06\n",
       "4273  2020-12-21    14946.0    32503.0  19823.51    0.0  2.257283e+06\n",
       "4274  2020-12-22    14946.0    32503.0  19823.51    0.0  2.227520e+06\n",
       "4275  2020-12-23    14946.0    32503.0  19823.51    0.0  2.223408e+06\n",
       "4276  2020-12-24    14946.0    32503.0  19823.51    0.0  2.223053e+06\n",
       "\n",
       "[4277 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14c8cc210>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(env.portfolioHistory[\"AUM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TargetModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 6,471\n",
      "Trainable params: 6,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Agent.Targetmodel.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_val(Agent.config, tag = \"NB_EPISODES_TRAIN\", default_value= 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConfigReader.Config at 0x14e31e550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 64, activation = \"relu\", input_dim = 64))\n",
    "model.add(Dense(units = 32, activation = \"relu\"))\n",
    "model.add(Dense(units = 7, activation = \"linear\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"temp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 6,471\n",
      "Trainable params: 6,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.reshape(1,64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Environments' from '/Users/ankitgupta/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/Environments.py'>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(Environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:01:39 INFO     Environments    Data Loaded!\n",
      "2021-02-01 17:01:39 INFO     Actions         Action Space set with 8 possible actions \n",
      "2021-02-01 17:01:39 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "actions = [\n",
    "    [-0.01,0.01],\n",
    "    [-0.02,0.02],\n",
    "    [-0.03,0.03],\n",
    "    [0.01,-0.01],\n",
    "    [0.02,-0.02],\n",
    "    [0.03,-0.03],\n",
    "    [-0.00,0.00],\n",
    "    [-1, -1]\n",
    "]\n",
    "\n",
    "env = Environments.Portfolio(assets = [\"APA\", \"BMY\"], initialWeight = [0.5, 0.5], \\\n",
    "                 nhistoricalDays = 2, \\\n",
    "                 actions = actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rew, _ = env.step([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, RMSprop, Adam\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.initializers import glorot_normal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network model\n",
    "# 2 networks required\n",
    "from collections import deque\n",
    "\n",
    "memory = deque(maxlen=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just 2 layers\n",
    "QNetwork = Sequential()\n",
    "\n",
    "\n",
    "layer1 = Dense(32, input_shape = (16,), activation = \"relu\", kernel_initializer=glorot_normal())\n",
    "#layer1 = Dense(32, input_shape = (64,), activation = \"relu\")\n",
    "layer2 = Dense(8, activation = \"linear\", kernel_initializer=glorot_normal())   # 7 actions\n",
    "QNetwork.add(layer1)\n",
    "QNetwork.add(layer2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.00025)\n",
    "loss = \"mse\"\n",
    "metrics = [loss] if loss in [\"mae\", \"mse\"] else [\"mse\"]\n",
    "\n",
    "        # compile the model\n",
    "QNetwork.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelHistory   = History()     # to store learning history\n",
    "callbacks = []\n",
    "callbacks.append(ModelHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetNetwork = Sequential()\n",
    "# just 2 layers\n",
    "#layer1 = Dense(32, input_shape = (64,), activation = \"relu\", kernel_initializer=glorot_normal())\n",
    "layer1 = Dense(32, input_shape = (16,), activation = \"relu\")\n",
    "\n",
    "layer2 = Dense(8, activation = \"linear\", kernel_initializer=glorot_normal())   # 7 actions\n",
    "TargetNetwork.add(layer1)\n",
    "TargetNetwork.add(layer2)\n",
    "\n",
    "optimizer = Adam(learning_rate = 0.00025)\n",
    "loss = \"mse\"\n",
    "metrics = [loss] if loss in [\"mae\", \"mse\"] else [\"mse\"]\n",
    "\n",
    "        # compile the model\n",
    "TargetNetwork.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "\n",
    "       \n",
    "\n",
    "TargetNetwork.set_weights(QNetwork.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 808\n",
      "Trainable params: 808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 808\n",
      "Trainable params: 808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(QNetwork.summary())\n",
    "print(TargetNetwork.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Actions.ActionSelection import EpsilonGreedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Actions.ActionSelection' from '/Users/ankitgupta/Documents/git/anks/MachineLearning/ReinforcementLearning/UseCases/PortfolioManagement/notebooks/../lib/Actions/ActionSelection.py'>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Actions.ActionSelection as act\n",
    "reload(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Actions.ActionSelection import EpsilonGreedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = EpsilonGreedy(1, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaction(state, env, trainingiterationCount = 1):\n",
    "    \n",
    "    # get one hot representation of state\n",
    "    #_state = getOneHotrepresentation(state, num_classes=self.env.observation_space.n)\n",
    "\n",
    "    state = np.array(state).reshape(1, env.observation_space.n)\n",
    "    \n",
    "    __state = normalizeX(state)\n",
    "    \n",
    "    _actionsValues      = QNetwork.predict(__state)[0] \n",
    "    _greedyActionIndex  = np.argmax(_actionsValues)\n",
    "\n",
    "    # epsilonGreedyaction        \n",
    "    action          = eps.chooseAction(trainingiterationCount, range(env.action_space.n), \\\n",
    "                                        optimalActionIndex=_greedyActionIndex)\n",
    "\n",
    "\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def updatememory(memory, currentState, currentAction, reward, nextState, dead):\n",
    "    if any(x is None for x in currentState) is False:\n",
    "        memory.append((currentState, currentAction, reward, nextState, dead))\n",
    "    return memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeX(X):\n",
    "    \n",
    "    a = np.array(list(zip(*X))[:-8]).T\n",
    "    \n",
    "    normalized_a = preprocessing.normalize(a)\n",
    "    \n",
    "    old = pd.DataFrame(X)\n",
    "    \n",
    "    columns = []\n",
    "    \n",
    "    for col in old.columns:\n",
    "        if int(col) >= len(old.columns) - 8:\n",
    "            columns.append(col)\n",
    "            \n",
    "    action = old[columns] \n",
    "    #action = pd.DataFrame(np.array(list(zip(*X))[-7:-8]).T)\n",
    "    new = pd.DataFrame(normalized_a)\n",
    "    \n",
    "    \n",
    "    output = new.merge(action, left_index = True, right_index = True)\n",
    "    \n",
    "    #temp = pd.DataFrame(X)\n",
    "    return np.array(output)\n",
    "    \n",
    "    # remove last columns from normalization, as they are just binary inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData(samples, env, targetNetwork):\n",
    "    \n",
    "    discountfactor = 0.01\n",
    "    \n",
    "    # -----X Train------\n",
    "    \n",
    "    # for all experience in batchsize\n",
    "    curStates       = list(list(zip(*samples)))[0]\n",
    "    actions         = list(list(zip(*samples)))[1]\n",
    "    nextStates      = list(list(zip(*samples)))[3]\n",
    "    rewards         = list(list(zip(*samples)))[2]\n",
    "    done            = list(list(zip(*samples)))[4]\n",
    "\n",
    "    \n",
    "    # Add pre-processing step if needed\n",
    "    inputStates     = np.array(curStates).reshape(len(curStates), env.observation_space.n)\n",
    "    \n",
    "    x_train = inputStates\n",
    "    \n",
    "    # -----Y Train------\n",
    "    nextStates      = np.array(nextStates).reshape(len(nextStates), env.observation_space.n)\n",
    "    \n",
    "    \n",
    "    # apply Q update\n",
    "    # y <-- r + gamma*max(Q_target(s_next))\n",
    "    \n",
    "    nextQvalues = targetNetwork.predict(nextStates)\n",
    "\n",
    "    y_train = np.zeros(shape = nextQvalues.shape)\n",
    "    \n",
    "    max_nextQvalues = list(map(max, nextQvalues))\n",
    "    \n",
    "    for index, action in enumerate(actions):\n",
    "        if done[index]:\n",
    "            y_train[index][int(action)] = rewards[index] \n",
    "        else:\n",
    "            y_train[index][int(action)] = rewards[index] + discountfactor * max_nextQvalues[index]\n",
    "            \n",
    "            \n",
    "    \n",
    "    # training data is set\n",
    "    return x_train, y_train\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:01:45 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpisodes = 5\n",
    "memory = []\n",
    "count = 0\n",
    "immediate_reward = []\n",
    "batch_size=32\n",
    "epoch = 1\n",
    "\n",
    "samplingStart = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999902.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.currentPortfolioValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"initialCash1\": constants.MILLION, \"minCash\": 0.02, \"transactionCost\": 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:01:49 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "loss = []\n",
    "\n",
    "# reset environment\n",
    "env.reset()\n",
    "dead = False\n",
    "samplingStartCounter = 0\n",
    "\n",
    "_currentState = env.currentState\n",
    "\n",
    "nbEpisodes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:01:54 INFO     Environments    Environment reset\n",
      "2021-02-01 17:03:20 INFO     Environments    Environment reset\n",
      "2021-02-01 17:04:46 INFO     Environments    Environment reset\n",
      "2021-02-01 17:08:31 INFO     Environments    Environment reset\n",
      "2021-02-01 17:09:58 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(nbEpisodes):\n",
    "    \n",
    "    # reset environment\n",
    "    env.reset()\n",
    "    dead = False\n",
    "    \n",
    "    _currentState = env.currentState\n",
    "    \n",
    "    while not dead:\n",
    "        \n",
    "        # get epsilon greeedy action\n",
    "        count += 1\n",
    "        if any(x is None for x in _currentState) is False:\n",
    "            actionIndex = getaction(_currentState, env, count)\n",
    "\n",
    "            action = env.action_space.actions[actionIndex]\n",
    "\n",
    "            # take a step in this direction\n",
    "            _nextState, _reward, dead = env.step(action)\n",
    "            #print(_reward, dead, action)\n",
    "            #immediate_reward.append(_reward)\n",
    "\n",
    "            # update memory\n",
    "            memory = updatememory(memory, _currentState, actionIndex, _reward, _nextState, dead)\n",
    "\n",
    "            # sample (uniform) from memory  (32 samples)\n",
    "            if len(memory) >= 100:\n",
    "\n",
    "                samples = random.sample(memory, 100)   \n",
    "\n",
    "                # update Q value\n",
    "\n",
    "                # get training data\n",
    "\n",
    "                x_train, y_train = getTrainingData(samples, env, TargetNetwork)\n",
    "\n",
    "                # normalize X data\n",
    "                x_train = normalizeX(x_train)\n",
    "\n",
    "                # train the model\n",
    "                QNetwork.fit(x=x_train, y = np.array(y_train), \\\n",
    "                                batch_size = batch_size, epochs = epoch, verbose = False, \n",
    "                                callbacks= callbacks)\n",
    "\n",
    "            # store weights \n",
    "            weights.append(QNetwork.layers[0].get_weights()[0])\n",
    "        #loss.append(cal)\n",
    "                \n",
    "        _currentState = _nextState\n",
    "\n",
    "\n",
    "    # after every episode, update the target network\n",
    "    TargetNetwork.set_weights(QNetwork.get_weights())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19921.51</td>\n",
       "      <td>98.00</td>\n",
       "      <td>9.999020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>14031.0</td>\n",
       "      <td>34493.0</td>\n",
       "      <td>19915.51</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.009564e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>13099.0</td>\n",
       "      <td>36451.0</td>\n",
       "      <td>19909.45</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.013972e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>12176.0</td>\n",
       "      <td>38423.0</td>\n",
       "      <td>19903.37</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1.018557e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>11868.0</td>\n",
       "      <td>39080.0</td>\n",
       "      <td>19901.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.020642e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>-194125501.0</td>\n",
       "      <td>49062598.0</td>\n",
       "      <td>-3751271.08</td>\n",
       "      <td>42.88</td>\n",
       "      <td>1.171359e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>-194354730.0</td>\n",
       "      <td>49118271.0</td>\n",
       "      <td>-3751973.90</td>\n",
       "      <td>702.82</td>\n",
       "      <td>1.559041e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>-194669688.0</td>\n",
       "      <td>49193696.0</td>\n",
       "      <td>-3752909.32</td>\n",
       "      <td>935.42</td>\n",
       "      <td>2.694799e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>-195242237.0</td>\n",
       "      <td>49325299.0</td>\n",
       "      <td>-3754526.20</td>\n",
       "      <td>1616.88</td>\n",
       "      <td>1.194085e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-195484609.0</td>\n",
       "      <td>49384024.0</td>\n",
       "      <td>-3755242.65</td>\n",
       "      <td>716.45</td>\n",
       "      <td>1.952349e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Asset_APA   Asset_BMY        Cash     Cost           AUM\n",
       "0     2003-12-31      14946.0     32503.0    19921.51    98.00  9.999020e+05\n",
       "1     2004-01-02      14031.0     34493.0    19915.51     6.00  1.009564e+06\n",
       "2     2004-01-05      13099.0     36451.0    19909.45     6.06  1.013972e+06\n",
       "3     2004-01-06      12176.0     38423.0    19903.37     6.08  1.018557e+06\n",
       "4     2004-01-07      11868.0     39080.0    19901.33     2.04  1.020642e+06\n",
       "...          ...          ...         ...         ...      ...           ...\n",
       "4272  2020-12-18 -194125501.0  49062598.0 -3751271.08    42.88  1.171359e+08\n",
       "4273  2020-12-21 -194354730.0  49118271.0 -3751973.90   702.82  1.559041e+08\n",
       "4274  2020-12-22 -194669688.0  49193696.0 -3752909.32   935.42  2.694799e+08\n",
       "4275  2020-12-23 -195242237.0  49325299.0 -3754526.20  1616.88  1.194085e+08\n",
       "4276  2020-12-24 -195484609.0  49384024.0 -3755242.65   716.45  1.952349e+08\n",
       "\n",
       "[4277 rows x 6 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21380, 16, 32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.flatten>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = plt.hist(weights[1000].flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.364982983759791"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1565313479259206e+20], 'mean_squared_error': [1.1565313e+20]}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-01 17:15:45 INFO     Environments    Environment reset\n"
     ]
    }
   ],
   "source": [
    "### run for 1 more episde with target network. No training\n",
    "nbEpisodes = 1\n",
    "actions = []\n",
    "for i in range(nbEpisodes):\n",
    "    \n",
    "    # reset environment\n",
    "    env.reset()\n",
    "    dead = False\n",
    "    \n",
    "    _currentState = env.currentState\n",
    "    \n",
    "    while not dead:\n",
    "        \n",
    "        # get epsilon greeedy action\n",
    "        count += 1\n",
    "        if any(x is None for x in _currentState) is False:\n",
    "            actionIndex = getaction(_currentState, env, count)\n",
    "            actions.append(actionIndex)\n",
    "\n",
    "            action = env.action_space.actions[actionIndex]\n",
    "\n",
    "            # take a step in this direction\n",
    "            _nextState, _reward, dead = env.step(action)\n",
    "            #immediate_reward.append(_reward)\n",
    "\n",
    "            # update memory\n",
    "            # memory = updatememory(memory, _currentState, actionIndex, _reward, _nextState, dead)\n",
    "\n",
    "\n",
    "        _currentState = _nextState\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Asset_APA</th>\n",
       "      <th>Asset_BMY</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Cost</th>\n",
       "      <th>AUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-12-31</td>\n",
       "      <td>14946.0</td>\n",
       "      <td>32503.0</td>\n",
       "      <td>19921.51</td>\n",
       "      <td>98.00</td>\n",
       "      <td>9.999020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>14031.0</td>\n",
       "      <td>34493.0</td>\n",
       "      <td>19915.51</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.009564e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>13099.0</td>\n",
       "      <td>36451.0</td>\n",
       "      <td>19909.45</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1.013972e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>12176.0</td>\n",
       "      <td>38423.0</td>\n",
       "      <td>19903.37</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1.018557e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>11253.0</td>\n",
       "      <td>40395.0</td>\n",
       "      <td>19897.26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>1.020893e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>-19553006.0</td>\n",
       "      <td>7077165.0</td>\n",
       "      <td>-205491.77</td>\n",
       "      <td>806.65</td>\n",
       "      <td>1.467576e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>-19840203.0</td>\n",
       "      <td>7146917.0</td>\n",
       "      <td>-206372.32</td>\n",
       "      <td>880.55</td>\n",
       "      <td>1.483469e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>-20139894.0</td>\n",
       "      <td>7218686.0</td>\n",
       "      <td>-207262.40</td>\n",
       "      <td>890.08</td>\n",
       "      <td>1.588613e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>-20477418.0</td>\n",
       "      <td>7296268.0</td>\n",
       "      <td>-208215.57</td>\n",
       "      <td>953.17</td>\n",
       "      <td>1.422079e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>-20766067.0</td>\n",
       "      <td>7366206.0</td>\n",
       "      <td>-209068.82</td>\n",
       "      <td>853.25</td>\n",
       "      <td>1.505801e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Asset_APA  Asset_BMY       Cash    Cost           AUM\n",
       "0     2003-12-31     14946.0    32503.0   19921.51   98.00  9.999020e+05\n",
       "1     2004-01-02     14031.0    34493.0   19915.51    6.00  1.009564e+06\n",
       "2     2004-01-05     13099.0    36451.0   19909.45    6.06  1.013972e+06\n",
       "3     2004-01-06     12176.0    38423.0   19903.37    6.08  1.018557e+06\n",
       "4     2004-01-07     11253.0    40395.0   19897.26    6.11  1.020893e+06\n",
       "...          ...         ...        ...        ...     ...           ...\n",
       "4272  2020-12-18 -19553006.0  7077165.0 -205491.77  806.65  1.467576e+08\n",
       "4273  2020-12-21 -19840203.0  7146917.0 -206372.32  880.55  1.483469e+08\n",
       "4274  2020-12-22 -20139894.0  7218686.0 -207262.40  890.08  1.588613e+08\n",
       "4275  2020-12-23 -20477418.0  7296268.0 -208215.57  953.17  1.422079e+08\n",
       "4276  2020-12-24 -20766067.0  7366206.0 -209068.82  853.25  1.505801e+08\n",
       "\n",
       "[4277 rows x 6 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.portfolioHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(actions, columns = [\"Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3941\n",
       "4      63\n",
       "7      53\n",
       "5      50\n",
       "6      46\n",
       "3      44\n",
       "0      43\n",
       "1      36\n",
       "Name: Index, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.Index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15599a390>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(env.portfolioHistory[\"AUM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1306, 1313, 3781, 3791, 3871]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[immediate_reward.index(item) for item in immediate_reward if item > 0.05 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_27_input to have shape (72,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f02bfd21cac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQNetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TENSORFLOW/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TENSORFLOW/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TENSORFLOW/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    386\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_27_input to have shape (72,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "QNetwork.predict(env.currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.currentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(porto)",
   "language": "python",
   "name": "porto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
